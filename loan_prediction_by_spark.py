# -*- coding: utf-8 -*-
"""LOAN PREDICTION BY SPARK

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EHeyGvieBOLkvxh8Kk2OWlRUIwXat9E5
"""
# -----------------------------
# 1. Imports
# -----------------------------
# PySpark
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, when
from pyspark.ml.feature import StringIndexer, Imputer, VectorAssembler
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from pyspark.ml.tuning import ParamGridBuilder, CrossValidator
from pyspark.ml import Pipeline

# Standard Python
import shutil
import glob
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay

# -----------------------------
# 2. Initialize Spark Session
# -----------------------------
spark = SparkSession.builder.appName('Loan_Prediction_Spark').getOrCreate()

# -----------------------------
# 3. Load Data
# -----------------------------
df = spark.read.csv("/content/loan_approval_dataset.csv", header=True, inferSchema=True)
df.show(5)
df.printSchema()

# -----------------------------
# 4. Basic Data Cleaning
# -----------------------------
df = df.drop('loan_id')  # Remove ID column
df = df.toDF(*[c.strip() for c in df.columns])  # Remove whitespace in column names

# Convert numeric columns to double
numeric_cols = ["residential_assets_value", "commercial_assets_value", "luxury_assets_value", "bank_asset_value"]
for col_name in numeric_cols:
    df = df.withColumn(col_name, col(col_name).cast("double"))

# -----------------------------
# 5. Feature Engineering
# -----------------------------
df = df.withColumn("total_assets",
    col("residential_assets_value") +
    col("commercial_assets_value") +
    col("luxury_assets_value") +
    col("bank_asset_value"))

df = df.withColumn("debt_to_income", col("loan_amount") / col("income_annum"))
df = df.withColumn("cibil_flag", when(col("cibil_score") < 650, 1).otherwise(0))
df = df.withColumn("is_self_employed", when(col("self_employed") == "Yes", 1).otherwise(0))
df = df.withColumn("is_graduate", when(col("education") == "Graduate", 1).otherwise(0))

# -----------------------------
# 6. Encode Categorical Columns
# -----------------------------
categorical_cols = ["education", "self_employed", "loan_status"]
for col_name in categorical_cols:
    indexer = StringIndexer(inputCol=col_name, outputCol=col_name + "_index")
    df = indexer.fit(df).transform(df)
df = df.drop(*categorical_cols)
df.show(5)

# -----------------------------
# 7. Prepare Pipeline
# -----------------------------
numeric_features = [
    'no_of_dependents', 'income_annum', 'loan_amount', 'loan_term', 'cibil_score',
    'residential_assets_value', 'commercial_assets_value', 'luxury_assets_value',
    'bank_asset_value', 'total_assets', 'debt_to_income', 'cibil_flag',
    'is_self_employed', 'is_graduate', 'education_index', 'self_employed_index'
]

# Imputer for missing numeric values
imputer = Imputer(inputCols=numeric_features, outputCols=[c + "_imputed" for c in numeric_features])

# Assemble features into a single vector
assembler = VectorAssembler(
    inputCols=[c + "_imputed" for c in numeric_features],
    outputCol="features"
)

# Logistic Regression Model
lr = LogisticRegression(featuresCol="features", labelCol="loan_status_index")

# Pipeline
pipeline = Pipeline(stages=[imputer, assembler, lr])

# Hyperparameter grid
paramGrid = ParamGridBuilder() \
    .addGrid(lr.regParam, [0.01, 0.1]) \
    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \
    .build()

# Evaluator
evaluator = BinaryClassificationEvaluator(labelCol="loan_status_index", metricName="areaUnderROC")

# Cross-validator
crossval = CrossValidator(
    estimator=pipeline,
    estimatorParamMaps=paramGrid,
    evaluator=evaluator,
    numFolds=3,
    parallelism=2
)

# -----------------------------
# 8. Train-Test Split & Fit
# -----------------------------
train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)
cv_model = crossval.fit(train_df)

# -----------------------------
# 9. Predictions & Evaluation
# -----------------------------
predictions = cv_model.transform(test_df)
test_auc = evaluator.evaluate(predictions)
print(f"Test AUC: {test_auc:.4f}")

# ROC Curve
preds_pd = predictions.select("loan_status_index", "probability").toPandas()
preds_pd['prob_1'] = preds_pd['probability'].apply(lambda x: float(x[1]))
fpr, tpr, _ = roc_curve(preds_pd['loan_status_index'], preds_pd['prob_1'])
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

# Confusion Matrix
preds_pd['prediction'] = preds_pd['prob_1'].apply(lambda x: 1 if x >= 0.5 else 0)
cm = confusion_matrix(preds_pd['loan_status_index'], preds_pd['prediction'])
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap='Blues')
plt.title("Confusion Matrix")
plt.show()

# -----------------------------
# 10. Save Predictions
# -----------------------------
result_df = predictions.select("loan_status_index", "prediction")
result_df.coalesce(1).write.mode("overwrite").csv("predictions_output", header=True)

# Move CSV to a single file
csv_file = glob.glob("predictions_output/*.csv")[0]
shutil.move(csv_file, "predictions.csv")
shutil.rmtree("predictions_output")
print("CSV file saved as 'predictions.csv'")

# -----------------------------
# 11. Save Model Summary
# -----------------------------
mean_cv_auc = np.mean(cv_model.avgMetrics)
with open("model_summary.txt", "w") as f:
    f.write("Loan Prediction Model Summary\n")
    f.write("============================\n")
    f.write(f"Mean Cross-Validated AUC: {mean_cv_auc:.4f}\n")
    f.write(f"Test AUC: {test_auc:.4f}\n\n")
    f.write("Comments:\n")
    f.write("- The model shows strong and consistent performance.\n")
    f.write("- Next steps: Tune hyperparameters or explore additional features.\n")
